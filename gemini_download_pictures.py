import requests
from playwright.async_api import async_playwright
from playwright_stealth import Stealth
import asyncio
import time
import aiofiles
import aiohttp
import os  # å¼•å…¥osåº“æ¥å¤„ç†è·¯å¾„

async def get_first_links(url):
    async with Stealth().use_async(async_playwright()) as p:
        browser=await p.chromium.launch(headless=True)
        content=await browser.new_context()
        page=await content.new_page()
        await page.goto(url,timeout=6000,wait_until="domcontentloaded")
        await page.wait_for_load_state("networkidle")
        first_links=[]
        first_links_locator=page.locator(".d-player-list a")
        count=await first_links_locator.count()
        if count>0:
            for i in range(count):
                locator=first_links_locator.nth(i)
                links=await locator.get_attribute("href")
                links="https://www.manhuazhan.com"+links
                first_links.append(links)
            return first_links
        else:
            print("No links found")
async def download_page(url: str):
    # --- è°ƒè¯•ä¿¡æ¯ ---
    print("ğŸš€ [1/7] 'download_page' å‡½æ•°å¼€å§‹æ‰§è¡Œ...")
    async  with Stealth().use_async(async_playwright()) as p:
        browser = await p.chromium.launch(headless=True)  # æ”¹ä¸ºTrueåœ¨åå°è¿è¡Œï¼Œé€šå¸¸æ›´å¿«
        # --- è°ƒè¯•ä¿¡æ¯ ---
        print("âœ… [2/7] æµè§ˆå™¨å·²å¯åŠ¨ã€‚")

        # æ£€æŸ¥cookiesæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists("cookies.json"):
            content = await browser.new_context(storage_state="cookies.json")
            print("â„¹ï¸ å·²åŠ è½½ cookies.json æ–‡ä»¶ã€‚")
        else:
            content = await browser.new_context()
            print("âš ï¸ æœªæ‰¾åˆ° cookies.json æ–‡ä»¶ï¼Œå°†ä»¥æœªç™»å½•çŠ¶æ€è¿è¡Œã€‚")

        page = await content.new_page()

        # --- è°ƒè¯•ä¿¡æ¯ ---
        print(f"â¡ï¸ [3/7] æ­£åœ¨å¯¼èˆªåˆ°é¡µé¢: {url} ...")
        await page.goto(url=url, timeout=60000)  # å¢åŠ äº†è¶…æ—¶æ—¶é—´
        print("âœ… é¡µé¢å¯¼èˆªåˆæ­¥å®Œæˆã€‚")

        # --- è°ƒè¯•ä¿¡æ¯ ---
        print("â³ [4/7] æ­£åœ¨ç­‰å¾…ç½‘ç»œæ´»åŠ¨ç©ºé—²...")
        await page.wait_for_load_state("networkidle")
        print("âœ… ç½‘ç»œå·²ç©ºé—²ã€‚")

        last_height = await page.evaluate("document.body.scrollHeight")

        button_locator = page.locator(".ViewAll-QuestionMainAction").first
        if await button_locator.count() > 0:
            print("ğŸ” æ‰¾åˆ°â€œæŸ¥çœ‹å…¨éƒ¨â€æŒ‰é’®ï¼Œå‡†å¤‡ç‚¹å‡»...")
            await button_locator.click()
            print("ğŸ‘ å·²ç‚¹å‡»â€œæŸ¥çœ‹å…¨éƒ¨â€æŒ‰é’®ã€‚")
        else:
            print("â„¹ï¸ æœªæ‰¾åˆ°â€œæŸ¥çœ‹å…¨éƒ¨â€æŒ‰é’®ã€‚")

        # --- è°ƒè¯•ä¿¡æ¯ ---
        print("ğŸ”„ [5/7] å¼€å§‹æ‰§è¡Œ150æ¬¡æ»šåŠ¨å¾ªç¯...")
        for i in range(150):
            # --- è°ƒè¯•ä¿¡æ¯ ---
            print(f"    æ­£åœ¨è¿›è¡Œç¬¬ {i + 1}/150 æ¬¡æ»šåŠ¨...")
            next_button_locator = page.locator(".ContentItem-more").first
            if await next_button_locator.count() > 0:
                print("    ğŸ” æ‰¾åˆ°â€œé˜…è¯»å…¨æ–‡â€æŒ‰é’®ï¼Œå‡†å¤‡ç‚¹å‡»...")
                await next_button_locator.click()
                print("    ğŸ‘ å·²ç‚¹å‡»â€œé˜…è¯»å…¨æ–‡â€æŒ‰é’®ã€‚")
            await page.keyboard.press("PageDown")
            await asyncio.sleep(1)
        print("ğŸŸ¢ æ»šåŠ¨å¾ªç¯å®Œæˆã€‚")

        all_pictures = []
        # --- è°ƒè¯•ä¿¡æ¯ ---
        print("ğŸ” [6/7] å¼€å§‹æå–æ‰€æœ‰å›¾ç‰‡é“¾æ¥...")
        #src_locator = page.locator(".RichContent-inner img[src^='https']")
        src_locator = page.locator(".chapterpic img")
        count = await src_locator.count()
        if count > 0:
            print(f"    å…±æ‰¾åˆ° {count} ä¸ªå›¾ç‰‡å…ƒç´ ï¼Œå¼€å§‹é€ä¸ªæå–é“¾æ¥...")
            for i in range(count):
                locator = src_locator.nth(i)
                picture = await locator.get_attribute("src")
                all_pictures.append(picture)
                # --- è°ƒè¯•ä¿¡æ¯ ---
                print(f"        ({i + 1}/{count}) æå–åˆ°é“¾æ¥ï¼Œæ­£åœ¨ç­‰å¾…1ç§’...")
                await asyncio.sleep(1)
            print(f"âœ… é“¾æ¥æå–å®Œæ¯•ï¼Œå…±è·å¾— {len(all_pictures)} ä¸ªé“¾æ¥ã€‚")
        else:
            print("ğŸ¤” æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡ã€‚")

    # --- è°ƒè¯•ä¿¡æ¯ ---
    print("âœ… [7/7] 'download_page' å‡½æ•°æ‰§è¡Œå®Œæ¯•ï¼Œå‡†å¤‡è¿”å›é“¾æ¥åˆ—è¡¨ã€‚")
    return all_pictures


async def main():
    # --- è°ƒè¯•ä¿¡æ¯ ---
    print("--- ç¨‹åºå¼€å§‹ ---")
    url = "https://www.manhuazhan.com/comic/252419"
    first_links = await get_first_links(url)
    print(first_links)

    # ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
    if not os.path.exists(all_output_path):
        os.makedirs(all_output_path)
        print(f"ğŸ“‚ å·²åˆ›å»ºæ–‡ä»¶å¤¹: {all_output_path}")

    all_pictures = await download_page(url)
    print(all_pictures)

    # --- è°ƒè¯•ä¿¡æ¯ ---
    if all_pictures:
        print(f"\n--- å¼€å§‹ä¸‹è½½ä»»åŠ¡ï¼Œå…± {len(all_pictures)} å¼ å›¾ç‰‡ ---")
    else:
        print("\n--- æœªè·å–åˆ°å›¾ç‰‡é“¾æ¥ï¼Œä»»åŠ¡ç»“æŸ ---")

    async with aiohttp.ClientSession() as session:
            for i, pictures in enumerate(all_pictures):
                # å¢åŠ ä¸€ä¸ªå¯¹ç©ºé“¾æ¥çš„åˆ¤æ–­ï¼Œé˜²æ­¢æŠ¥é”™
                try:
                    if not pictures:
                        print(f"âš ï¸ ç¬¬ {i + 1} ä¸ªé“¾æ¥ä¸ºç©ºï¼Œå·²è·³è¿‡ã€‚")
                        continue

                    async with session.get(pictures) as response:
                        content = await response.read()
                        output_path = f"{all_output_path}/{i}.jpg"
                        async with aiofiles.open(output_path, "wb") as f:
                            await f.write(content)
                            # æ‚¨åŸæœ‰çš„æˆåŠŸä¿¡æ¯å·²ç»å¾ˆå¥½äº†
                            print("ç¬¬" + str(i + 1) + "å¼ ç…§ç‰‡ä¸‹è½½æˆåŠŸ")
                except Exception as e:
                    continue






    # --- è°ƒè¯•ä¿¡æ¯ ---
    print("\n--- æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œç¨‹åºç»“æŸ ---")


if __name__ == "__main__":
    asyncio.run(main())